{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.core.display_functions import clear_output\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_values = ['Iris-setosa','Iris-versicolor','Iris-virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_from_checkpoint = False\n",
    "\n",
    "if(not read_from_checkpoint):\n",
    "    all_data = pd.read_csv(\"iris.csv\")\n",
    "    all_data = all_data.sample( frac=1) # shuffle\n",
    "    for species_value in species_values:\n",
    "        all_data['Species_' + species_value] = (all_data['Species'] == species_value).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "    cutoff = math.floor(len(all_data) * 0.8)\n",
    "\n",
    "    training_data = all_data.iloc[:cutoff,:].reset_index(drop=True)\n",
    "    testing_data = all_data.iloc[cutoff:,:].reset_index(drop=True)\n",
    "\n",
    "    os.makedirs(\"checkpoint\",exist_ok=True)\n",
    "    training_data.to_csv('checkpoint/trainingdata.csv',index=False)\n",
    "    testing_data.to_csv('checkpoint/testingdata.csv',index=False)\n",
    "else:\n",
    "    training_data = pd.read_csv('checkpoint/trainingdata.csv')\n",
    "    testing_data = pd.read_csv('checkpoint/testingdata.csv')\n",
    "\n",
    "\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1699085966866,
     "user": {
      "displayName": "Wayne Borg (wayne1512)",
      "userId": "14031780574936101840"
     },
     "user_tz": -60
    },
    "id": "IjxPYkDCaM3r"
   },
   "outputs": [],
   "source": [
    "def sigmoid(logit): # sigmoid\n",
    "  return 1/(1+ np.exp(-logit))\n",
    "\n",
    "def leaky_relu(logit): # leaky relu\n",
    "  return np.where(logit>0.0,logit,0.01*logit)\n",
    "\n",
    "def softmax(logit): # softmax\n",
    "  return np.exp(logit)/np.sum(np.exp(logit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bad_facts_fig, bad_facts_ax = plt.subplots()\n",
    "bad_facts_ln, = bad_facts_ax.plot([], [], label='Bad Facts')\n",
    "\n",
    "bad_facts_ax.set_xlabel('Epoch')\n",
    "bad_facts_ax.set_ylabel('Bad Facts')\n",
    "bad_facts_ax.legend(loc='upper right')\n",
    "\n",
    "def update_graphs(): \n",
    "    bad_facts_ln.set_data(range(len(bad_facts_per_epoch)),bad_facts_per_epoch)\n",
    "    bad_facts_fig.gca().relim()\n",
    "    bad_facts_fig.gca().autoscale_view()\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    display(bad_facts_fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "layer0_size = 4\n",
    "layer1_size = 4\n",
    "layer2_size = 3\n",
    "\n",
    "\n",
    "layer_1_dropout = np.zeros(layer1_size)\n",
    "\n",
    "layer0_outputs = np.zeros(layer0_size)\n",
    "layer1_outputs = np.zeros(layer1_size)\n",
    "layer2_outputs = np.zeros(layer2_size)\n",
    "\n",
    "\n",
    "layer1_logit = np.zeros(layer1_size)\n",
    "layer2_logit = np.zeros(layer2_size)\n",
    "\n",
    "\n",
    "layer1_weights = np.random.uniform(-1,1,size=(layer0_size,layer1_size))\n",
    "layer2_weights = np.random.uniform(-1,1,size=(layer1_size,layer2_size))\n",
    "\n",
    "\n",
    "layer2_delta = np.zeros(layer2_size)\n",
    "layer1_delta = np.zeros(layer1_size)\n",
    "\n",
    "update_graph_live = True\n",
    "update_graph_intervals = 1000\n",
    "\n",
    "error_threshold = 0.2\n",
    "learning_rate = 0.2\n",
    "layer_1_dropout_prob = 0.0\n",
    "\n",
    "layer1_activation_function = \"sigmoid\"\n",
    "layer2_activation_function = \"softmax\"\n",
    "\n",
    "bad_facts_per_epoch = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def forward_prop_layer(layer_inputs, layer_weights, layer_logit, layer_outputs,activation_function, use_dropout = False, layer_dropout = None, layer_dropout_probability = 0):\n",
    "    np.matmul(layer_inputs,layer_weights,out=layer_logit)\n",
    "        \n",
    "    if activation_function == \"sigmoid\":\n",
    "        layer_outputs[:] = sigmoid(layer_logit)\n",
    "    elif activation_function == \"leaky_relu\":\n",
    "        layer_outputs[:] = leaky_relu(layer_logit)\n",
    "    elif activation_function == \"softmax\":\n",
    "        layer_outputs[:] = softmax(layer_logit)\n",
    "    else:\n",
    "        raise Exception(\"Unknown activation function\",activation_function)\n",
    "    \n",
    "    if use_dropout:\n",
    "        layer_dropout[:] = np.random.rand(*layer_dropout.shape)>layer_dropout_probability\n",
    "        layer_outputs *= layer_dropout\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def forward_prop(inputs,use_dropout):\n",
    "    layer0_outputs[:] = np.array(inputs)\n",
    "    forward_prop_layer(layer0_outputs,layer1_weights,layer1_logit,layer1_outputs,layer1_activation_function,use_dropout,layer_1_dropout,layer_1_dropout_prob)\n",
    "    forward_prop_layer(layer1_outputs,layer2_weights,layer2_logit,layer2_outputs,layer2_activation_function)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop_output_layer(layer_outputs,targets,layer_weights,layer_delta,prev_layer_ouputs,activation_function):\n",
    "    \n",
    "    if activation_function == \"sigmoid\":\n",
    "        layer_delta[:] = layer_outputs*(1-layer_outputs) * (targets-layer_outputs)\n",
    "    elif activation_function == \"leaky_relu\":\n",
    "        layer_delta[:] = np.where(layer_outputs>0.0,1.0,0.01) * (targets-layer_outputs)\n",
    "    elif activation_function == \"softmax\":\n",
    "        layer_delta[:] = layer_outputs - targets\n",
    "    else:\n",
    "        raise Exception(\"Unknown activation function\",activation_function)\n",
    "    \n",
    "    layer_delta[:] = layer_outputs*(1-layer_outputs) * (targets-layer_outputs)\n",
    "\n",
    "    delta_W = np.outer(prev_layer_ouputs,layer_delta.T) * learning_rate\n",
    "\n",
    "    layer_weights += delta_W\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def back_prop_hidden_layer(output_weights,layer_outputs,layer_weights,prev_layer_outputs,next_layer_deltas,layer_delta,activation_function):\n",
    "\n",
    "\n",
    "    sums = []\n",
    "\n",
    "    for p in range(output_weights.shape[0]):\n",
    "        sum = 0\n",
    "        for q in range(output_weights.shape[1]):\n",
    "            sum += next_layer_deltas[q] * output_weights[p,q]\n",
    "        sums.append(sum)\n",
    "\n",
    "\n",
    "    if activation_function == \"sigmoid\":\n",
    "        layer_delta[:] = layer_outputs*(1-layer_outputs) * np.array(sums)\n",
    "    elif activation_function == \"leaky_relu\":\n",
    "        layer_delta[:] = np.where(layer_outputs>0.0,1.0,0.01) * np.array(sums)\n",
    "    else:\n",
    "        raise Exception(\"Unknown activation function\",activation_function)\n",
    "\n",
    "    delta_W = np.outer(prev_layer_outputs,layer_delta.T) * learning_rate\n",
    "\n",
    "    layer_weights += delta_W"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(target):\n",
    "    back_prop_output_layer(layer2_outputs,target,layer2_weights,layer2_delta,layer1_outputs,layer2_activation_function)\n",
    "    back_prop_hidden_layer(layer2_weights,layer1_outputs,layer1_weights,layer0_outputs,layer2_delta,layer1_delta,layer1_activation_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train():\n",
    "    for epoch in range(10000):\n",
    "        bad_facts = 0\n",
    "        for i in range(len(training_data.index)):\n",
    "    \n",
    "            \n",
    "    \n",
    "            forward_prop(training_data.loc[i,['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].values.astype(float),True)\n",
    "    \n",
    "            target = training_data.loc[i,['Species_Iris-setosa','Species_Iris-versicolor','Species_Iris-virginica']].values.astype(float)\n",
    "                \n",
    "            error = target - layer2_outputs\n",
    "    \n",
    "            output_outside_threshold = np.abs(error) > error_threshold\n",
    "    \n",
    "            if np.any(output_outside_threshold):\n",
    "                bad_facts += 1\n",
    "                \n",
    "                back_prop(target)\n",
    "            \n",
    "             \n",
    "        \n",
    "        bad_facts_per_epoch.append(bad_facts)\n",
    "        \n",
    "        if update_graph_live and epoch%update_graph_intervals == 0:\n",
    "            update_graphs()\n",
    "            \n",
    "        if bad_facts == 0:\n",
    "            return\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test():\n",
    "    success = []\n",
    "    \n",
    "    for i in range(len(testing_data.index)):\n",
    "    \n",
    "            \n",
    "    \n",
    "            forward_prop(testing_data.loc[i,['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].values.astype(float),False)\n",
    "            \n",
    "            target = testing_data.loc[i,['Species_Iris-setosa','Species_Iris-versicolor','Species_Iris-virginica']].values.astype(float)\n",
    "    \n",
    "            error = target - layer2_outputs\n",
    "    \n",
    "            output_outside_threshold = np.abs(error) > error_threshold\n",
    "            \n",
    "            success.append(not output_outside_threshold.any())\n",
    "        \n",
    "    return success"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train()\n",
    "test()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO7L9LRsSseqFflOKrhX2g9",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
